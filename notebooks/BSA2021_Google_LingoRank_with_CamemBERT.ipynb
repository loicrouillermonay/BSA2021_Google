{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BSA2021_Google_LingoRank_with_CamemBERT_v3_b4-_30e.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bac26ef42bd549e5a0df132c1f8e9dc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_78b8921d96504258b473ea136c7c57eb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8894d01a578c47c891194c836cb3e486",
              "IPY_MODEL_857d3da6cb4240dca3087f44144e5120"
            ]
          }
        },
        "78b8921d96504258b473ea136c7c57eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8894d01a578c47c891194c836cb3e486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d3c55996c85642b0880cbe455f9fc316",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 810912,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 810912,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e0290efb05b24c3a83aaf482d7e11ea3"
          }
        },
        "857d3da6cb4240dca3087f44144e5120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_075a6fa468c1416199c6d78625c41446",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 811k/811k [00:20&lt;00:00, 39.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_863a97938d9a42c0b5903928f8d2282e"
          }
        },
        "d3c55996c85642b0880cbe455f9fc316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e0290efb05b24c3a83aaf482d7e11ea3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "075a6fa468c1416199c6d78625c41446": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "863a97938d9a42c0b5903928f8d2282e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QDd0_NbhwSb",
        "outputId": "96a71335-e0c7-4716-b5fd-a6c28b9b9f1d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNS0ecn-cLBJ"
      },
      "source": [
        "!pip install transformers==2.8.0\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKTsS8qmHKM0"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import torch\n",
        "import string\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import CamembertForSequenceClassification, CamembertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "punctuation = string.punctuation\n",
        "# Credits to Olivier. (2021, January 5). Analyse de sentiments avec CamemBERT. Le Data Scientist. https://ledatascientist.com/analyse-de-sentiments-avec-camembert/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvPWbsrRa9nJ",
        "outputId": "aaea1d80-95da-4a3c-f05f-404ff8da1501"
      },
      "source": [
        "dataset = pd.read_csv(\"/content/max-dataset.csv\")\n",
        "dataset.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9174 entries, 0 to 9173\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Text        9174 non-null   object\n",
            " 1   Difficulty  9174 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 143.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shklKqs4cCyT"
      },
      "source": [
        "# Transpose A1-C2 scale into 0 to 5 \n",
        "difficulties = ['A1', 'A2', 'B1', 'B2', 'C1', 'C2']\n",
        "for index, difficulty in zip(range(len(difficulties)), difficulties):\n",
        "    dataset['Difficulty'] = dataset['Difficulty'].replace([difficulty], index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe53y0spnwdD"
      },
      "source": [
        "# text preprocessing: remove punctuation and lowercase (results are worse)\n",
        "# punctuation = punctuation.replace('-', '')\n",
        "# punctuation = punctuation.replace('~', '')\n",
        "\n",
        "# def preprocess_text(text: string):\n",
        "#     sentence = ''.join([ word for word in text if word not in punctuation ])\n",
        "#     return (sentence).lower()\n",
        "\n",
        "# dataset.Text = dataset.Text.apply(lambda x: preprocess_text(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnMDFTv5fGWG"
      },
      "source": [
        "# Filter by target variable in order to create a balanced train and test set.\n",
        "a1_X = dataset[dataset.Difficulty == 0]['Text']\n",
        "a2_X = dataset[dataset.Difficulty == 1]['Text']\n",
        "b1_X = dataset[dataset.Difficulty == 2]['Text']\n",
        "b2_X = dataset[dataset.Difficulty == 3]['Text']\n",
        "c1_X = dataset[dataset.Difficulty == 4]['Text']\n",
        "c2_X = dataset[dataset.Difficulty == 5]['Text']\n",
        "\n",
        "a1_y = dataset[dataset.Difficulty == 0]['Difficulty']\n",
        "a2_y = dataset[dataset.Difficulty == 1]['Difficulty']\n",
        "b1_y = dataset[dataset.Difficulty == 2]['Difficulty']\n",
        "b2_y = dataset[dataset.Difficulty == 3]['Difficulty']\n",
        "c1_y = dataset[dataset.Difficulty == 4]['Difficulty']\n",
        "c2_y = dataset[dataset.Difficulty == 5]['Difficulty']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk23lJWcfMZA"
      },
      "source": [
        "# Train_test_split for each target variable\n",
        "X_train_a1, X_test_a1, y_train_a1, y_test_a1 = train_test_split(a1_X, a1_y, test_size=0.1, random_state=707)\n",
        "X_train_a2, X_test_a2, y_train_a2, y_test_a2 = train_test_split(a2_X, a2_y, test_size=0.1, random_state=707)\n",
        "X_train_b1, X_test_b1, y_train_b1, y_test_b1 = train_test_split(b1_X, b1_y, test_size=0.1, random_state=707)\n",
        "X_train_b2, X_test_b2, y_train_b2, y_test_b2 = train_test_split(b2_X, b2_y, test_size=0.1, random_state=707)\n",
        "X_train_c1, X_test_c1, y_train_c1, y_test_c1 = train_test_split(c1_X, c1_y, test_size=0.1, random_state=707)\n",
        "X_train_c2, X_test_c2, y_train_c2, y_test_c2 = train_test_split(c2_X, c2_y, test_size=0.1, random_state=707)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e7ZLss8fQnt"
      },
      "source": [
        "# Group X, y\n",
        "texts_train = X_train_a1.append([X_train_a2, X_train_b1, X_train_b2, X_train_c1, X_train_c2], ignore_index=True).values.tolist()\n",
        "texts_test = X_test_a1.append([X_test_a2, X_test_b1, X_test_b2, X_test_c1, X_test_c2], ignore_index=True).values.tolist()\n",
        "labels_train = y_train_a1.append([y_train_a2, y_train_b1, y_train_b2, y_train_c1, y_train_c2], ignore_index=True).values.tolist()\n",
        "labels_test = y_test_a1.append([y_test_a2, y_test_b1, y_test_b2, y_test_c1, y_test_c2], ignore_index=True).values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a5vW39cfH51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "bac26ef42bd549e5a0df132c1f8e9dc9",
            "78b8921d96504258b473ea136c7c57eb",
            "8894d01a578c47c891194c836cb3e486",
            "857d3da6cb4240dca3087f44144e5120",
            "d3c55996c85642b0880cbe455f9fc316",
            "e0290efb05b24c3a83aaf482d7e11ea3",
            "075a6fa468c1416199c6d78625c41446",
            "863a97938d9a42c0b5903928f8d2282e"
          ]
        },
        "outputId": "2105174f-4be2-4f0a-f701-146a24a2c352"
      },
      "source": [
        "TOKENIZER = CamembertTokenizer.from_pretrained('camembert-base', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bac26ef42bd549e5a0df132c1f8e9dc9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=810912.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfs9Ot9N4jdz"
      },
      "source": [
        "def preprocess(raw_texts, labels=None):\n",
        "    \"\"\"\n",
        "    Takes raw data as argument and returns a pytorch dataloader.\n",
        "\n",
        "    Args\n",
        "        raw_texts (array-like) : A list of texts in the form of 'str'\n",
        "        \n",
        "        labels : a labels list from 0 to 5\n",
        "    \n",
        "    Returns\n",
        "        inputs_ids, attention_masks, labels(optionel) : PyTorch object that contains tokenized and encoded versions of raw data\n",
        "    \"\"\"\n",
        "\n",
        "    \n",
        "\n",
        "    encoded_batch = TOKENIZER.batch_encode_plus(raw_texts,\n",
        "                                                add_special_tokens=True,\n",
        "                                                pad_to_max_length=True,\n",
        "                                                return_attention_mask=True,\n",
        "                                                return_tensors = 'pt')\n",
        "    if labels:\n",
        "        labels = torch.tensor(labels)\n",
        "        return encoded_batch['input_ids'], encoded_batch['attention_mask'], labels\n",
        "    return encoded_batch['input_ids'], encoded_batch['attention_mask']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_Sm1dvCddc6"
      },
      "source": [
        "input_ids, attention_mask, labels_train = preprocess(texts_train, labels_train)\n",
        "# Combine the training inputs into a TensorDataset\n",
        "train_dataset = TensorDataset(\n",
        "    input_ids,\n",
        "    attention_mask,\n",
        "    labels_train)\n",
        "\n",
        "input_ids, attention_mask, labels_test = preprocess(texts_test, labels_test)\n",
        "# Combine the validation inputs into a TensorDataset\n",
        "validation_dataset = TensorDataset(\n",
        "    input_ids,\n",
        "    attention_mask,\n",
        "    labels_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaIdMxlirdFc"
      },
      "source": [
        "# size of 4, 8, 16 or 32.\n",
        "batch_size = 4\n",
        "\n",
        "# Create the DataLoaders\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size)\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            validation_dataset,\n",
        "            sampler = SequentialSampler(validation_dataset),\n",
        "            batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoTafgwY_pyB",
        "outputId": "f58134a4-5f5a-4043-b7bb-a9f386d2c9e9"
      },
      "source": [
        "try:\n",
        "    state_dict = torch.load(\"/content/drive/MyDrive/Colab Notebooks/lingorank-v3.pt\")\n",
        "    print(\"Loading trained model...\")\n",
        "    model = CamembertForSequenceClassification.from_pretrained(\n",
        "    'camembert-base',\n",
        "    state_dict=state_dict,\n",
        "    num_labels = 6)\n",
        "    print(\"Trained model loaded!\")\n",
        "except Exception as e:\n",
        "    print(\"Enable to load trained model.\")\n",
        "    print(e)\n",
        "    model = CamembertForSequenceClassification.from_pretrained(\n",
        "        'camembert-base',\n",
        "        num_labels = 6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enable to load trained model.\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/lingorank-v3.pt'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7vUl8O2gAUM"
      },
      "source": [
        "def predict(texts, model=model):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        input_ids, attention_mask = preprocess(texts)\n",
        "        retour = model(input_ids, attention_mask=attention_mask)\n",
        "        return torch.argmax(retour[0], dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjAyMcRW0bVW"
      },
      "source": [
        "def evaluate(texts, labels, metric='report'):\n",
        "    predictions = predict(texts)\n",
        "    if metric == 'report':\n",
        "        return metrics.classification_report(labels, predictions, zero_division=0)\n",
        "    elif metric == 'matrix':\n",
        "        return metrics.confusion_matrix(labels, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEvYTvehrgkY"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0DoJqlPwbZS"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # Learning Rate - Default is 5e-5\n",
        "                  eps = 1e-8 # Adam Epsilon  - Default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llBtKS_QbzXU"
      },
      "source": [
        "import gc \n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELf3ehrNxY3k",
        "outputId": "ac109505-337c-45df-98f1-72521013e5e5"
      },
      "source": [
        "if torch.cuda.is_available():  \n",
        "  dev = \"cuda:0\" \n",
        "else:  \n",
        "  dev = \"cpu\"  \n",
        "device = torch.device(dev)  \n",
        "torch.cuda.set_device(0)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Training loop\n",
        "training_stats = []\n",
        "                                                                                \n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]\n",
        "# (Note that this is not the same as the number of training samples)\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "\n",
        "# This variable will evaluate the convergence on the training\n",
        "consecutive_epochs_with_no_improve = 0\n",
        "\n",
        "# Training\n",
        "for epoch in range(0, epochs):\n",
        "    \n",
        "    print(\"\")\n",
        "    print(f'########## Epoch {epoch} / {epochs} ##########')\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 1000 batches.\n",
        "        if step % 1000 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = time.time() - t0\n",
        "            \n",
        "            # Report progress\n",
        "            print(f'  Batch {step}  of  {len(train_dataloader)}    Elapsed: {format_time(elapsed)}.')\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the 'device' using the 'to' method\n",
        "        #\n",
        "        # 'batch' contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: skills \n",
        "        input_id = batch[0].to(device)\n",
        "        attention_mask = batch[1].to(device)\n",
        "        labels = batch[2].to(device)\n",
        "\n",
        "        # Clear any previously calculated gradients before performing a backward pass\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch)\n",
        "        # the loss (because we provided skills) and the \"logits\"--the model\n",
        "        # outputs prior to activation\n",
        "        loss, logits = model(input_id, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=attention_mask, \n",
        "                             labels=labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. 'loss' is a Tensor containing a\n",
        "        # single value; the '.item()' function just returns the Python value \n",
        "        # from the tensor\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)   \n",
        "\n",
        "    if epoch > 0:\n",
        "        if min([stat['Training Loss'] for stat in training_stats]) <= avg_train_loss:\n",
        "            # i.e. If there is not improvement\n",
        "            consecutive_epochs_with_no_improve += 1\n",
        "        else:\n",
        "            # If there is improvement\n",
        "            consecutive_epochs_with_no_improve = 0\n",
        "            print(\"Model saved!\")\n",
        "            torch.save(model.state_dict(), \"/content/drive/MyDrive/Colab Notebooks/lingorank-v3.pt\")\n",
        "    \n",
        "    # Measure how long this epoch took\n",
        "    training_time = time.time() - t0\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "    \n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Training Time': training_time,\n",
        "        }\n",
        "    )\n",
        "    if consecutive_epochs_with_no_improve == 2:\n",
        "        print(\"Stop training : The loss has not changed since 2 epochs!\")\n",
        "        break\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(\"Model saved!\")\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/metrics-v3.json', 'w+') as outfile:\n",
        "    json.dump(training_stats, outfile)\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/Colab Notebooks/lingorank-v3.pt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "########## Epoch 0 / 50 ##########\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 1000  of  2064    Elapsed: 0:04:45.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:30.\n",
            "\n",
            "  Average training loss: 1.31\n",
            "  Training epoch took: 587.7840957641602\n",
            "\n",
            "########## Epoch 1 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:45.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:30.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.94\n",
            "  Training epoch took: 588.2549843788147\n",
            "\n",
            "########## Epoch 2 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:45.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:30.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.68\n",
            "  Training epoch took: 588.5307531356812\n",
            "\n",
            "########## Epoch 3 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:45.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:29.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.53\n",
            "  Training epoch took: 587.3015303611755\n",
            "\n",
            "########## Epoch 4 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:44.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:28.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.43\n",
            "  Training epoch took: 586.5536725521088\n",
            "\n",
            "########## Epoch 5 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:44.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:27.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.34\n",
            "  Training epoch took: 584.946840763092\n",
            "\n",
            "########## Epoch 6 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:42.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:24.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Training epoch took: 582.3925416469574\n",
            "\n",
            "########## Epoch 7 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:42.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:25.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.23\n",
            "  Training epoch took: 582.5780909061432\n",
            "\n",
            "########## Epoch 8 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:42.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:24.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epoch took: 581.8037307262421\n",
            "\n",
            "########## Epoch 9 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:42.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:24.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.17\n",
            "  Training epoch took: 581.8677637577057\n",
            "\n",
            "########## Epoch 10 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:42.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:24.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.16\n",
            "  Training epoch took: 582.1664161682129\n",
            "\n",
            "########## Epoch 11 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:42.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:24.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Training epoch took: 581.8092720508575\n",
            "\n",
            "########## Epoch 12 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:42.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:23.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Training epoch took: 580.9131078720093\n",
            "\n",
            "########## Epoch 13 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:42.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:23.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.11\n",
            "  Training epoch took: 581.0593626499176\n",
            "\n",
            "########## Epoch 14 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:41.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:23.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Training epoch took: 580.5593295097351\n",
            "\n",
            "########## Epoch 15 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:42.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:23.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Training epoch took: 581.2027108669281\n",
            "\n",
            "########## Epoch 16 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:41.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:23.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.08\n",
            "  Training epoch took: 581.2248647212982\n",
            "\n",
            "########## Epoch 17 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:42.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:23.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.08\n",
            "  Training epoch took: 581.3482351303101\n",
            "\n",
            "########## Epoch 18 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:42.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:23.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.08\n",
            "  Training epoch took: 581.3043873310089\n",
            "\n",
            "########## Epoch 19 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:42.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:24.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epoch took: 581.7195477485657\n",
            "\n",
            "########## Epoch 20 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:42.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:25.\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epoch took: 582.6175174713135\n",
            "\n",
            "########## Epoch 21 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:42.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:25.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epoch took: 582.7384221553802\n",
            "\n",
            "########## Epoch 22 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:42.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:25.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.06\n",
            "  Training epoch took: 582.5676004886627\n",
            "\n",
            "########## Epoch 23 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:42.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:25.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.06\n",
            "  Training epoch took: 582.4834127426147\n",
            "\n",
            "########## Epoch 24 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:42.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:24.\n",
            "\n",
            "  Average training loss: 0.06\n",
            "  Training epoch took: 582.3290772438049\n",
            "\n",
            "########## Epoch 25 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:42.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:24.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epoch took: 582.2575423717499\n",
            "\n",
            "########## Epoch 26 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:42.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:24.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epoch took: 582.1586353778839\n",
            "\n",
            "########## Epoch 27 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:42.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:25.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epoch took: 582.5199544429779\n",
            "\n",
            "########## Epoch 28 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:42.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:25.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epoch took: 582.5418515205383\n",
            "\n",
            "########## Epoch 29 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:42.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:25.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epoch took: 582.7360084056854\n",
            "\n",
            "########## Epoch 30 / 50 ##########\n",
            "Training...\n",
            "  Batch 1000  of  2064    Elapsed: 0:04:42.\n",
            "  Batch 2000  of  2064    Elapsed: 0:09:25.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epoch took: 582.5313732624054\n",
            "Stop training : The loss has not changed since 2 epochs!\n",
            "Model saved!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb0e_ENz8_Eq"
      },
      "source": [
        "device = torch.device('cpu') \n",
        "model.to(device)\n",
        "\n",
        "# Make predictions on the test dataset\n",
        "predictions = []\n",
        "for sentence in texts_test:\n",
        "    predictions.append(predict([sentence]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HId_35BKPUlw",
        "outputId": "2d69a55c-25f2-41d4-d261-ffe244ddcc09"
      },
      "source": [
        "print(metrics.classification_report(predictions, labels_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.82      0.83       146\n",
            "           1       0.76      0.71      0.74       192\n",
            "           2       0.70      0.73      0.71       146\n",
            "           3       0.79      0.64      0.71       193\n",
            "           4       0.68      0.76      0.72       144\n",
            "           5       0.67      0.89      0.77        99\n",
            "\n",
            "    accuracy                           0.74       920\n",
            "   macro avg       0.74      0.76      0.74       920\n",
            "weighted avg       0.75      0.74      0.74       920\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yF0X_utPJhT",
        "outputId": "977d2d37-b9db-4279-8a58-88c82f8e5664"
      },
      "source": [
        "metrics.confusion_matrix(predictions, labels_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[119,  19,   4,   3,   1,   0],\n",
              "       [ 23, 136,  23,   5,   2,   3],\n",
              "       [  0,  19, 106,  12,   5,   4],\n",
              "       [  0,   3,  18, 124,  33,  15],\n",
              "       [  0,   1,   1,  12, 109,  21],\n",
              "       [  0,   0,   0,   1,  10,  88]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Benp8RcRb7XV",
        "outputId": "7abd6ca7-c912-48dd-ae68-9ea38b601f8a"
      },
      "source": [
        "# Loop for checking specific wrongs predictions \n",
        "for x, y, z in zip(predictions, labels_test, texts_test):\n",
        "    if int(x) == 0:\n",
        "        if y == 1:\n",
        "            print(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ainsi, Pierre a le privilège d'admirer chaque jour l'un des monuments les plus visités au monde !\n",
            "Je vais ensuite prendre ma douche dans ma salle-de-bain.\n",
            "À bientôt!\n",
            "Nous avons déménagé en France, parce qu'elle a toujours aimé la culture de ce pays.\n",
            "Je propose des spécialités de la région lyonnaise.\n",
            "J'imagine que les week-ends doivent être bien remplis !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sdo6ELiKTbZ",
        "outputId": "2f27a4dd-582d-4d2f-c660-d88138c10738"
      },
      "source": [
        "device = torch.device('cpu') \n",
        "model.to(device)\n",
        "\n",
        "# Predicts each word perceived difficulty in a sentence.\n",
        "predict(\"Dans un premier temps, nous nous demanderons si le travail n’est qu’une activité imposée par l’extérieur contre la volonté de l’Homme, puis dans un deuxième temps nous nous interrogerons sur le fait que le travail est une activité que l’être humain s’impose librement à lui-même.\".split(' '))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}