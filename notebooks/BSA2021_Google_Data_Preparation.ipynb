{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr_core_news_sm==2.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.3.0/fr_core_news_sm-2.3.0.tar.gz (14.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.7 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /Users/loic/opt/miniconda3/lib/python3.8/site-packages (from fr_core_news_sm==2.3.0) (2.3.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/loic/opt/miniconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/loic/opt/miniconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (2.25.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/loic/opt/miniconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/loic/opt/miniconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (1.0.5)\n",
      "Requirement already satisfied: setuptools in /Users/loic/opt/miniconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (51.0.0.post20201207)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/loic/opt/miniconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (1.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/loic/opt/miniconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (4.54.1)\n",
      "Requirement already satisfied: thinc==7.4.1 in /Users/loic/opt/miniconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (7.4.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/loic/opt/miniconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/loic/opt/miniconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (0.8.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/loic/opt/miniconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (3.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/loic/opt/miniconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (2.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/loic/opt/miniconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (1.19.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/loic/opt/miniconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/loic/opt/miniconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/loic/opt/miniconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/loic/opt/miniconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (3.0.4)\n",
      "Building wheels for collected packages: fr-core-news-sm\n",
      "  Building wheel for fr-core-news-sm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fr-core-news-sm: filename=fr_core_news_sm-2.3.0-py3-none-any.whl size=14718367 sha256=b391ab18912d8519e1ee81b23142d25484375dcb0551c26b0e8c5fe858e91572\n",
      "  Stored in directory: /private/var/folders/6n/4rrpn39918n57t4rcsptw5nc0000gn/T/pip-ephem-wheel-cache-3aogq127/wheels/48/ca/2e/2a3756cab2ba8745ce853319ba0d44b1efb8892a86320e9633\n",
      "Successfully built fr-core-news-sm\n",
      "Installing collected packages: fr-core-news-sm\n",
      "Successfully installed fr-core-news-sm-2.3.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('fr_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from pycaret.classification import *\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "punctuation = string.punctuation\n",
    "stopwords = set(stopwords.words('french'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from the respository\n",
    "data = pd.read_csv('../data/max-dataset.csv')\n",
    "data_google = pd.read_csv('../data/google-full-dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9174 entries, 0 to 9173\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Text        9174 non-null   object\n",
      " 1   Difficulty  9174 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 143.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A2    1779\n",
       "C1    1594\n",
       "B2    1563\n",
       "B1    1518\n",
       "A1    1419\n",
       "C2    1301\n",
       "Name: Difficulty, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Difficulty.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity Recognition\n",
    "def return_NER(sentence):\n",
    "    # Tokenize the sentence\n",
    "    doc = nlp(sentence)\n",
    "    # Return text and label for each sentence\n",
    "    return [(X.text, X.label_) for X in doc.ents]\n",
    "\n",
    "# Part-Of-Speech\n",
    "def return_POS(sentence):\n",
    "    # Tokenize the sentence\n",
    "    doc = nlp(sentence)\n",
    "    # Return tag of each token\n",
    "    return [(X, X.pos_) for X in doc]\n",
    "\n",
    "def NER_counter(sentence: string):\n",
    "    # Take a sentence with its text & label and couint each elements\n",
    "    ner = return_NER(sentence)\n",
    "    counter = Counter([t[1] for t in ner])\n",
    "    return counter\n",
    "\n",
    "def POS_counter(sentence: string):\n",
    "    # Take a token with its tags and count each elements\n",
    "    pos = return_POS(sentence)\n",
    "    counter = Counter([t[1] for t in pos])\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction of features to better understand the texts\n",
    "def features_extraction(dataframe: pd.DataFrame):\n",
    "    dataframe[\"num_chars\"] = dataframe[\"Text\"].apply(len)\n",
    "    dataframe[\"num_words\"] = dataframe[\"Text\"].apply(lambda x: len(x.split()))\n",
    "    dataframe[\"avg_word_length\"] = dataframe['Text'].apply(lambda x: np.sum([len(w) for w in x.split()]) / len(x.split()))\n",
    "    dataframe['num_stopwords'] = dataframe['Text'].apply(lambda x: np.sum([1 for word in x.split(' ') if word in stopwords]))\n",
    "    dataframe['ratio_num_words_over_stopwords'] = dataframe['num_words'] / dataframe['num_stopwords']\n",
    "    \n",
    "    # Iterate over each row in the dataframe and get some specific features\n",
    "    for index, row in data.iterrows():\n",
    "        # Part-Of-Speech\n",
    "        counter_pos = POS_counter(row['Text'])\n",
    "        for x in counter_pos:\n",
    "            dataframe.loc[index, x] = counter_pos[x]\n",
    "        \n",
    "        # Entity Recognizer\n",
    "        counter_ner = NER_counter(row['Text'])\n",
    "        for x in counter_ner:\n",
    "            dataframe.loc[index, x] = counter_ner[x]\n",
    "        \n",
    "        # Number of words before the first verb in each sentence\n",
    "        current_pos = return_POS(row.Text)\n",
    "        iter_current_pos = [str(y) for t in current_pos for y in t]\n",
    "        if 'VERB' in iter_current_pos:\n",
    "            dataframe.loc[index, 'num_words_before_first_verb'] = (iter_current_pos.index('VERB') + 1) // 2\n",
    "        else:\n",
    "            dataframe.loc[index, 'num_words_before_first_verb'] = 0\n",
    "            \n",
    "    return dataframe.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 3s, sys: 317 ms, total: 3min 4s\n",
      "Wall time: 3min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create a dataset containing the basic data and the extracted features\n",
    "dataset = features_extraction(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_words</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>num_stopwords</th>\n",
       "      <th>ratio_num_words_over_stopwords</th>\n",
       "      <th>PRON</th>\n",
       "      <th>VERB</th>\n",
       "      <th>DET</th>\n",
       "      <th>...</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>ORG</th>\n",
       "      <th>ADV</th>\n",
       "      <th>MISC</th>\n",
       "      <th>PER</th>\n",
       "      <th>X</th>\n",
       "      <th>SYM</th>\n",
       "      <th>PART</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>SPACE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Je recherche une personne pour garder mes enfa...</td>\n",
       "      <td>A1</td>\n",
       "      <td>64</td>\n",
       "      <td>13</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Il faut être disponible pour travailler les je...</td>\n",
       "      <td>A1</td>\n",
       "      <td>95</td>\n",
       "      <td>15</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vous devez habiter dans le centre de Limoges o...</td>\n",
       "      <td>A1</td>\n",
       "      <td>66</td>\n",
       "      <td>12</td>\n",
       "      <td>4.583333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Expérience avec les enfants souhaitée.</td>\n",
       "      <td>A1</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Si vous êtes intéressé, appelez-moi.</td>\n",
       "      <td>A1</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9169</th>\n",
       "      <td>La vieille acquiesça de la tête, sous sa grand...</td>\n",
       "      <td>C2</td>\n",
       "      <td>168</td>\n",
       "      <td>25</td>\n",
       "      <td>5.720000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9170</th>\n",
       "      <td>Il fallait qu’il débitât les nouvelles apprise...</td>\n",
       "      <td>C2</td>\n",
       "      <td>70</td>\n",
       "      <td>11</td>\n",
       "      <td>5.454545</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9171</th>\n",
       "      <td>Vous eussiez dit deux éclairs bleuâtres, parei...</td>\n",
       "      <td>C2</td>\n",
       "      <td>158</td>\n",
       "      <td>24</td>\n",
       "      <td>5.583333</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9172</th>\n",
       "      <td>Elle dénoua le ruban qui attachait le manche d...</td>\n",
       "      <td>C2</td>\n",
       "      <td>102</td>\n",
       "      <td>19</td>\n",
       "      <td>4.421053</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9173</th>\n",
       "      <td>Il y avait dans sa voix, dans son regard, dans...</td>\n",
       "      <td>C2</td>\n",
       "      <td>122</td>\n",
       "      <td>23</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.642857</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9174 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text Difficulty  num_chars  \\\n",
       "0     Je recherche une personne pour garder mes enfa...         A1         64   \n",
       "1     Il faut être disponible pour travailler les je...         A1         95   \n",
       "2     Vous devez habiter dans le centre de Limoges o...         A1         66   \n",
       "3                Expérience avec les enfants souhaitée.         A1         38   \n",
       "4                  Si vous êtes intéressé, appelez-moi.         A1         36   \n",
       "...                                                 ...        ...        ...   \n",
       "9169  La vieille acquiesça de la tête, sous sa grand...         C2        168   \n",
       "9170  Il fallait qu’il débitât les nouvelles apprise...         C2         70   \n",
       "9171  Vous eussiez dit deux éclairs bleuâtres, parei...         C2        158   \n",
       "9172  Elle dénoua le ruban qui attachait le manche d...         C2        102   \n",
       "9173  Il y avait dans sa voix, dans son regard, dans...         C2        122   \n",
       "\n",
       "      num_words  avg_word_length  num_stopwords  \\\n",
       "0            13         4.000000            5.0   \n",
       "1            15         5.400000            3.0   \n",
       "2            12         4.583333            5.0   \n",
       "3             5         6.800000            2.0   \n",
       "4             5         6.400000            2.0   \n",
       "...         ...              ...            ...   \n",
       "9169         25         5.720000            6.0   \n",
       "9170         11         5.454545            2.0   \n",
       "9171         24         5.583333            6.0   \n",
       "9172         19         4.421053           10.0   \n",
       "9173         23         4.347826           14.0   \n",
       "\n",
       "      ratio_num_words_over_stopwords  PRON  VERB  DET  ...  PROPN  ORG  ADV  \\\n",
       "0                           2.600000   1.0   2.0  2.0  ...    0.0  0.0  0.0   \n",
       "1                           5.000000   1.0   2.0  1.0  ...    0.0  0.0  0.0   \n",
       "2                           2.400000   1.0   3.0  2.0  ...    0.0  0.0  0.0   \n",
       "3                           2.500000   0.0   1.0  1.0  ...    0.0  0.0  0.0   \n",
       "4                           2.500000   2.0   2.0  0.0  ...    0.0  0.0  0.0   \n",
       "...                              ...   ...   ...  ...  ...    ...  ...  ...   \n",
       "9169                        4.166667   1.0   3.0  5.0  ...    1.0  0.0  1.0   \n",
       "9170                        5.500000   2.0   3.0  2.0  ...    0.0  0.0  0.0   \n",
       "9171                        4.000000   2.0   6.0  1.0  ...    0.0  0.0  2.0   \n",
       "9172                        1.900000   3.0   3.0  5.0  ...    0.0  0.0  0.0   \n",
       "9173                        1.642857   3.0   2.0  5.0  ...    0.0  0.0  2.0   \n",
       "\n",
       "      MISC  PER    X  SYM  PART  INTJ  SPACE  \n",
       "0      0.0  0.0  0.0  0.0   0.0   0.0    0.0  \n",
       "1      0.0  0.0  0.0  0.0   0.0   0.0    0.0  \n",
       "2      0.0  0.0  0.0  0.0   0.0   0.0    0.0  \n",
       "3      0.0  0.0  0.0  0.0   0.0   0.0    0.0  \n",
       "4      0.0  0.0  0.0  0.0   0.0   0.0    0.0  \n",
       "...    ...  ...  ...  ...   ...   ...    ...  \n",
       "9169   0.0  0.0  0.0  0.0   0.0   0.0    1.0  \n",
       "9170   0.0  0.0  0.0  0.0   0.0   0.0    0.0  \n",
       "9171   0.0  0.0  0.0  0.0   0.0   0.0    1.0  \n",
       "9172   0.0  0.0  0.0  0.0   0.0   0.0    0.0  \n",
       "9173   0.0  0.0  0.0  0.0   0.0   0.0    0.0  \n",
       "\n",
       "[9174 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset on the repository to avoid having to recompute all the features when running the notebook again\n",
    "dataset.to_csv('../data/max-dataset-with-features.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of a BOW with the dataset to later help with CamemBERT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../data/max-dataset-with-features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.5 s, sys: 341 ms, total: 48.8 s\n",
      "Wall time: 49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Use of spacy tokenizer to create and preprocess tokens\n",
    "def spacy_tokenizer(text: string):    \n",
    "    # create spacy object\n",
    "    mytokens = [token.text for token in nlp(text)]\n",
    "    \n",
    "    # remove stop words and punctuation\n",
    "    mytokens = [ word for word in mytokens if word not in stopwords and word not in punctuation ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens\n",
    "\n",
    "# tokenizer \n",
    "count = CountVectorizer(ngram_range = (1,2), tokenizer=spacy_tokenizer)\n",
    "bow = count.fit_transform(dataset.Text)\n",
    "\n",
    "# create the dataframe\n",
    "dataset_bow = pd.DataFrame(\n",
    "    bow.todense(), \n",
    "    columns = count.get_feature_names()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\\t</th>\n",
       "      <th>\\n</th>\n",
       "      <th>\\n\\n</th>\n",
       "      <th>\\n</th>\n",
       "      <th>\\n  avouions</th>\n",
       "      <th>\\n  cloîtrées</th>\n",
       "      <th>\\n  donnais</th>\n",
       "      <th>\\n  furtifs</th>\n",
       "      <th>\\n  l’</th>\n",
       "      <th>\\n  où</th>\n",
       "      <th>...</th>\n",
       "      <th>−</th>\n",
       "      <th>− allégorie</th>\n",
       "      <th>− beautés</th>\n",
       "      <th>− d'</th>\n",
       "      <th>− enchantent</th>\n",
       "      <th>− exhibait</th>\n",
       "      <th>− premier</th>\n",
       "      <th>− qu'</th>\n",
       "      <th>− quand</th>\n",
       "      <th>− tel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9170</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9171</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9172</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9173</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9174 rows × 79959 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      \\t  \\n  \\n\\n  \\n   \\n  avouions  \\n  cloîtrées  \\n  donnais  \\\n",
       "0      0   0     0    0             0              0            0   \n",
       "1      0   0     0    0             0              0            0   \n",
       "2      0   0     0    0             0              0            0   \n",
       "3      0   0     0    0             0              0            0   \n",
       "4      0   0     0    0             0              0            0   \n",
       "...   ..  ..   ...  ...           ...            ...          ...   \n",
       "9169   0   0     0    1             0              0            0   \n",
       "9170   0   0     0    0             0              0            0   \n",
       "9171   0   1     0    0             0              0            0   \n",
       "9172   0   0     0    0             0              0            0   \n",
       "9173   0   0     0    0             0              0            0   \n",
       "\n",
       "      \\n  furtifs  \\n  l’  \\n  où  ...  −  − allégorie  − beautés  − d'  \\\n",
       "0               0       0       0  ...  0            0          0     0   \n",
       "1               0       0       0  ...  0            0          0     0   \n",
       "2               0       0       0  ...  0            0          0     0   \n",
       "3               0       0       0  ...  0            0          0     0   \n",
       "4               0       0       0  ...  0            0          0     0   \n",
       "...           ...     ...     ...  ... ..          ...        ...   ...   \n",
       "9169            0       1       0  ...  0            0          0     0   \n",
       "9170            0       0       0  ...  0            0          0     0   \n",
       "9171            0       0       0  ...  0            0          0     0   \n",
       "9172            0       0       0  ...  0            0          0     0   \n",
       "9173            0       0       0  ...  0            0          0     0   \n",
       "\n",
       "      − enchantent  − exhibait  − premier  − qu'  − quand  − tel  \n",
       "0                0           0          0      0        0      0  \n",
       "1                0           0          0      0        0      0  \n",
       "2                0           0          0      0        0      0  \n",
       "3                0           0          0      0        0      0  \n",
       "4                0           0          0      0        0      0  \n",
       "...            ...         ...        ...    ...      ...    ...  \n",
       "9169             0           0          0      0        0      0  \n",
       "9170             0           0          0      0        0      0  \n",
       "9171             0           0          0      0        0      0  \n",
       "9172             0           0          0      0        0      0  \n",
       "9173             0           0          0      0        0      0  \n",
       "\n",
       "[9174 rows x 79959 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_bow_augmented = pd.concat([dataset.loc[ : , dataset.columns != 'Text'], dataset_bow], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_bow_augmented.to_csv('../data/bow-dataset-1-2ngrams.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
